{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vSMat73wNrXB"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!apt-get install libglu1-mesa\n",
        "!pip install sinabs tonic"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To remove later cell:\n",
        "\n",
        "- every neuron 16bit, every synapse 8bit. Follow the following table for layer:\n",
        "https://sinabs.readthedocs.io/en/v2.0.0/speck/overview.html"
      ],
      "metadata": {
        "id": "rxCp8-7q2FO1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LOAD DATA"
      ],
      "metadata": {
        "id": "bBW1E22TvqA9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#### LOAD DATA ####\n",
        "\n",
        "import tonic\n",
        "from tonic.transforms import ToFrame\n",
        "from tonic.datasets import nmnist\n",
        "from tonic import transforms\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "root = \"/\"\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToFrame(sensor_size=tonic.datasets.DVSGesture.sensor_size, n_time_bins=16, include_incomplete=True),\n",
        "    lambda x: x.astype(np.float32),\n",
        "])\n",
        "\n",
        "testset = tonic.datasets.DVSGesture(save_to=os.path.join(root, \"tutorials/data\"), train=False, transform=transform)\n",
        "trainset = tonic.datasets.DVSGesture(save_to=os.path.join(root, \"tutorials/data\"), train=True, transform=transform)\n",
        "\n",
        "events, label = trainset[0]\n",
        "events[0].shape"
      ],
      "metadata": {
        "id": "VFsZwkliYdlP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03a86054-3a60-458d-b6f6-178ffda28fb5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 128, 128)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DEFINE MODEL"
      ],
      "metadata": {
        "id": "3QpioG6ivsop"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#### DEFINE MODEL ###\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from typing import List\n",
        "import sinabs\n",
        "import sinabs.layers as sl\n",
        "\n",
        "class DVSGestureNet(nn.Module):\n",
        "    def __init__(self, channels=128, *args, **kwargs):\n",
        "        super().__init__()\n",
        "\n",
        "        conv = []\n",
        "        for i in range(5):\n",
        "            if conv.__len__() == 0:\n",
        "                in_channels = 2\n",
        "                stride=2\n",
        "            else:\n",
        "                in_channels = channels\n",
        "                stride=1\n",
        "\n",
        "            conv.append(nn.Conv2d(in_channels, channels, kernel_size=3, padding=1, stride=stride))\n",
        "            conv.append(nn.BatchNorm2d(channels))\n",
        "            conv.append(sl.IAFSqueeze(*args, **kwargs))\n",
        "            if i != 0:\n",
        "              conv.append(sl.SumPool2d(2, 2))\n",
        "\n",
        "\n",
        "        self.conv_fc = nn.Sequential(\n",
        "            *conv,\n",
        "\n",
        "            nn.Flatten(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(channels * 4 * 4, 512),\n",
        "            sl.IAFSqueeze(*args, **kwargs),\n",
        "\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, 110),\n",
        "            sl.IAFSqueeze(*args, **kwargs),\n",
        "            nn.Linear(110,11),\n",
        "            #sl.SumPool2d((10,1), stride=(10,1)),\n",
        "            sl.IAFSqueeze(*args, **kwargs),\n",
        "\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        return self.conv_fc(x)\n",
        "\n",
        "    def return_sequential(self):\n",
        "      return self.conv_fc"
      ],
      "metadata": {
        "id": "iMZO-xZzQCr3"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = DVSGestureNet(batch_size=1, channels=8)"
      ],
      "metadata": {
        "id": "Y-UHVcZcik8j"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "net.return_sequential()\n",
        "#summary(net, (2,128,128))\n",
        "x = torch.randn(1,2,128,128)\n",
        "net(x)"
      ],
      "metadata": {
        "id": "af_rmepHirKn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c94bd38-b57e-4093-b37a-7f255610a4bb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., -0., -0., 0., 0., 0., 0., -0., 0., 0.]],\n",
              "       grad_fn=<ViewBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TRAIN MODEL"
      ],
      "metadata": {
        "id": "u7jNiSPSv3Sr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import SGD, Adam\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from tqdm import tqdm\n",
        "\n",
        "epochs = 1\n",
        "lr = 1e-3\n",
        "batch_size = 4\n",
        "num_workers = 4\n",
        "n_time_steps=16\n",
        "device = \"cuda:0\" # \"cpu\"\n",
        "shuffle = True\n",
        "\n",
        "snn_train_dataloader = DataLoader(trainset, batch_size=batch_size, num_workers=num_workers, drop_last=True, shuffle=True)\n",
        "snn_test_dataloader = DataLoader(testset, batch_size=batch_size, num_workers=num_workers, drop_last=True, shuffle=False)\n",
        "\n",
        "net = net.to(device=device)\n",
        "\n",
        "optimizer = Adam(params=net.parameters(), lr=lr)\n",
        "criterion = CrossEntropyLoss()\n",
        "\n",
        "for e in range(epochs):\n",
        "\n",
        "    # train\n",
        "    train_p_bar = tqdm(snn_train_dataloader)\n",
        "    for data, label in train_p_bar:\n",
        "        # reshape the input from [Batch, Time, Channel, Height, Width] into [Batch*Time, Channel, Height, Width]\n",
        "        data = data.reshape(-1, 2, 128, 128).to(dtype=torch.float, device=device)\n",
        "        label = label.to(dtype=torch.long, device=device)\n",
        "        # forward\n",
        "        optimizer.zero_grad()\n",
        "        output = net(data)\n",
        "        # reshape the output from [Batch*Time,num_classes] into [Batch, Time, num_classes]\n",
        "        output = output.reshape(batch_size, n_time_steps, -1)\n",
        "        # accumulate all time-steps output for final prediction\n",
        "        output = output.sum(dim=1)\n",
        "        loss = criterion(output, label)\n",
        "        #print(loss.device)\n",
        "        # backward\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # detach the neuron states and activations from current computation graph(necessary)\n",
        "        for layer in net.modules():\n",
        "            if isinstance(layer, sl.StatefulLayer):\n",
        "                for name, buffer in layer.named_buffers():\n",
        "                    buffer.detach_()\n",
        "\n",
        "        # set progressing bar\n",
        "        train_p_bar.set_description(f\"Epoch {e} - BPTT Training Loss: {round(loss.item(), 4)}\")\n",
        "\n",
        "    # validate\n",
        "    correct_predictions = []\n",
        "    with torch.no_grad():\n",
        "        test_p_bar = tqdm(snn_test_dataloader)\n",
        "        for data, label in test_p_bar:\n",
        "            # reshape the input from [Batch, Time, Channel, Height, Width] into [Batch*Time, Channel, Height, Width]\n",
        "            data = data.reshape(-1, 2, 34, 34).to(dtype=torch.float, device=device)\n",
        "            label = label.to(dtype=torch.long, device=device)\n",
        "            # forward\n",
        "            output = net(data)\n",
        "            # reshape the output from [Batch*Time,num_classes] into [Batch, Time, num_classes]\n",
        "            output = output.reshape(batch_size, n_time_steps, -1)\n",
        "            # accumulate all time-steps output for final prediction\n",
        "            output = output.sum(dim=1)\n",
        "            # calculate accuracy\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            # compute the total correct predictions\n",
        "            correct_predictions.append(pred.eq(label.view_as(pred)))\n",
        "            # set progressing bar\n",
        "            test_p_bar.set_description(f\"Epoch {e} - BPTT Testing Model...\")\n",
        "\n",
        "        correct_predictions = torch.cat(correct_predictions)\n",
        "        print(f\"Epoch {e} - BPTT accuracy: {correct_predictions.sum().item()/(len(correct_predictions))*100}%\")"
      ],
      "metadata": {
        "id": "B02foXVWOFfe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        },
        "outputId": "9fd5e63c-7507-40d0-95ca-0b1de3149be0"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "  0%|          | 0/269 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "  0%|          | 0/269 [00:03<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-cba40c3a28f5>\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m#print(loss.device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m# backward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m             )\n\u001b[0;32m--> 522\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    523\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    267\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/function.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    287\u001b[0m             )\n\u001b[1;32m    288\u001b[0m         \u001b[0muser_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvjp_fn\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mvjp_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mFunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvjp\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mbackward_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0muser_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_jvp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sinabs/activation/spike_generation.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(ctx, grad_output)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_output\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;34m\"\"\"\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mv_mem\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msurrogate_grad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv_mem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspike_threshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mgrad_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad_output\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DEPLOY MODEL ON SPECK"
      ],
      "metadata": {
        "id": "C21nrRo4vv1F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import SGD\n",
        "from tqdm.notebook import tqdm\n",
        "from torch.nn import CrossEntropyLoss"
      ],
      "metadata": {
        "id": "Ca7xg-UTc71h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sinabs.backend.dynapcnn import io\n",
        "print(io.device_types)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrkJUINhYRvd",
        "outputId": "29713401-7264-4dad-db8a-d686e3f1cde3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'speck': 'speck', 'speck2b': 'Speck2bTestboard', 'speck2devkit': 'Speck2DevKit', 'speck2btiny': 'Speck2bDevKitTiny', 'speck2e': 'Speck2eTestBoard', 'speck2edevkit': 'Speck2eDevKit', 'speck2fmodule': 'Speck2fModuleDevKit', 'speck2fdevkit': 'Speck2fDevKit', 'dynapse1devkit': 'Dynapse1DevKit', 'davis346': 'Davis 346', 'davis240': 'Davis 240', 'dvxplorer': 'DVXplorer', 'pollendevkit': 'PollenDevKit', 'dynapcnndevkit': 'DynapcnnDevKit', 'dynapse2': 'DYNAP-SE2 DevBoard', 'dynapse2_stack': 'DYNAP-SE2 Stack'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sinabs.backend.dynapcnn import DynapcnnNetwork\n",
        "\n",
        "# cpu_snn = snn_convert.to(device=\"cpu\")\n",
        "cpu_snn = net.return_sequential().to(device=\"cpu\")\n",
        "dynapcnn = DynapcnnNetwork(snn=cpu_snn, input_shape=(2, 128, 128), discretize=True, dvs_input=False)\n",
        "devkit_name = \"speck2edevkit\"\n",
        "\n",
        "# use the `to` method of DynapcnnNetwork to deploy the SNN to the devkit\n",
        "dynapcnn.to(device=devkit_name, chip_layers_ordering=\"auto\",monitor_layers=[-1])\n",
        "print(f\"The SNN is deployed on the core: {dynapcnn.chip_layers_ordering}\")"
      ],
      "metadata": {
        "id": "R4i3dSHC83S2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "2531c96e-2c95-439e-d2f7-fcd05a795798"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Network is valid\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'speck2edevkit:0'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-ddf92d887271>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# use the `to` method of DynapcnnNetwork to deploy the SNN to the devkit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mdynapcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevkit_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchip_layers_ordering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"auto\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmonitor_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"The SNN is deployed on the core: {dynapcnn.chip_layers_ordering}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sinabs/backend/dynapcnn/dynapcnn_network.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, device, chip_layers_ordering, monitor_layers, config_modifier, slow_clk_frequency)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0;31m# Apply configuration to device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamna_device\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamna_device\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_configuration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sinabs/backend/dynapcnn/io.py\u001b[0m in \u001b[0;36mopen_device\u001b[0;34m(device_id)\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0mdevice_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstandardize_device_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0mdevice_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_device_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m     \u001b[0mdevice_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdevice_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m     \u001b[0mdevice_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msamna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'speck2edevkit:0'"
          ]
        }
      ]
    }
  ]
}